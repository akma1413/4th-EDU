# 제출 시 제목을 Session07 이름으로 해주세요.

# Recommendation Algorithm

# Surprise 내장 영화 데이터(ml-100k)를 로드하여 “UBCF hardcoding.ipynb” 내의 코드를 따라 UBCF를 해주세요.
# 코사인 유사도를 기준으로 KNN 알고리즘을 작성해주세요. (k는 임의로 설정)
# sklearn 모듈 내의 kfold 함수를 이용해 5-fold Cross Validation을 시행하고, Absolute Error의 평균을 최종적으로 출력해주세요.


recommended algo quest

from collections import defaultdict; import pandas as pd; import numpy as np
import surprise
import pandas as pd
import numpy as np
from collections import defaultdict, Counter

data = surprise.Dataset.load_builtin('ml-100k')               # surprise에서 데이터를 가져오는 코드입니다
df = pd.DataFrame(data.raw_ratings, columns = ['movieId', 'userId', 'rating', 'timestamp'])

cnt = Counter(df['userId']) # 이하부터 ubcf 하드코딩 세션 파일 중 필요한 부분을 취했습니다
idx_sorted = sorted(list(cnt.keys()), key= lambda x: cnt[x], reverse = True)
idx = np.zeros(len(df)) 
for i in idx_sorted[:400]:
    idx += (df['userId'] == i)
idx = np.array(idx, dtype=bool)

new_df = df[idx].iloc[:,:3]
del df

from sklearn.model_selection import train_test_split
train, test = train_test_split(new_df, test_size=0.3, random_state=42)
del new_df; del idx 

utility_matrix = train.pivot(index='userId', columns='movieId', values='rating').fillna(0)

def cos_sim(x, y, more_than = 5):
    idx = (x>0) & (y>0) 
    if sum(idx) < more_than: return 0
    x_n = x[idx]
    y_n = y[idx]
    return np.dot(x_n, y_n) ** 2 / (np.dot(x_n, x_n) * np.dot(y_n, y_n))

def find_neighbors(utility_matrix, k, sim_fun):
    sim_dict = {}
    for i in utility_matrix.index: 
        ranking = [(0,0)] * k
        for j in utility_matrix.index.drop(i): 
            ranking.append((j, sim_fun(utility_matrix.loc[i], utility_matrix.loc[j]))) 
            ranking = sorted(ranking, key=lambda x: -x[1])[:k]
        sim_dict[i] = ranking
    return sim_dict

neighbors = find_neighbors(utility_matrix, 10, cos_sim)

def testing(test, neighbors, utility_matrix): 
    predicted = []
    movies = utility_matrix.columns # train data에 있는 영화 목록
    for i in range(len(test)): 
        movie = test.iloc[i,0]; user = test.iloc[i,1]
        if (user not in neighbors) or (movie not in movies):
            predicted.append(None)
        else: predicted.append(prediction(user, movie, neighbors, utility_matrix)) 
    return predicted

def prediction(user, movie, neighbors, utility_matrix):
    my_neighbors = neighbors[user] 
    rates = []
    for i, _ in my_neighbors:  
        r = utility_matrix.loc[i, movie] 
        if r > 0: rates.append(r) 
    if rates == []: return None
    else: return sum(rates)/len(rates)

test['prediction'] = testing(test, neighbors, utility_matrix)

from surprise.model_selection import KFold  # KFold를 import

sim_options = {'name': 'cosine'}    # 코사인 유사도를 취하겠다는 것
algo = surprise.KNNWithMeans(sim_options=sim_options)

np.random.seed(0) 
acc = np.zeros(5)
cv = KFold(5)
for i, (train, test) in enumerate(cv.split(data)):
    algo.fit(train)    # train셋을 학습시키고
    predictions = algo.test(test)  # test셋을 테스트 시킴
    acc[i] = surprise.accuracy.mae(predictions, verbose=True) #surprise에서 accuracy 모듈 내의 mae를 구함
acc.mean() #윗줄 코드로 도출된 5개의 mae의 평균을 구함

# SQL 1

# QUEST 1. quest1 table 이용. 10,000원 이상이거나 재고액이 200,000이상인 제품들의 no, 가격, 재고수량, 재고액을 구해보세요. (열 이름 별칭 사용)

# QUEST 2. sample2 table 이용. 사람들의 이름, 나이, 성인 여부를 구해보세요 (열 이름 별칭 사용)

quest2 solution(quest1은 세션시간에 확인받음)

select name, year(current_timestamp())-year(birthday)+1 as age,
case
	when year(birthday) < 2000 then 'yes'
	when year(birthday) >=2000 then 'no'
end as adult from quest2
